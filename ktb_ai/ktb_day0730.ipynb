{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnJtwaOI/vzNmTl4owHeFR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyeong8465/KTB/blob/main/ktb_ai/ktb_day0730.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgZCQzGa9g0W"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "생성형 인공지능 4\n",
        "- Llama\n",
        "메타에서 만든 대형 언어 모델\n",
        "적은 자원으로도 다양한 자연어 처리 작업에서 높은 성능 발휘\n",
        "아키텍처: Transformer, Pre-normalization, SwiGLU, Rotary Embeddings\n",
        "\n",
        "- Fine-tuning\n",
        "사전 학습된 대규모 언어 모델(LLM)을 특정 작업에 맞게 추가 학습시키는 과정\n",
        "사전 학습: 대규모 데이터 셋을 사용하여 모델이 언어의 일반적인 패턴과 구조 학습, 다양한 언어 구조와 표현 학습\n",
        "파인 튜닝: 특정 작업에 맞게 추가 학습\n",
        "\n",
        "파인 튜닝은 왜 필요할까?\n",
        "    특정 작업에 대해 적은 양의 데이터로도 높은 성능을 발휘\n",
        "    상대적으로 적은 데이터와 자원으로 수행 가능\n",
        "    장점: 특정 작업에 맞춘 높은 성능, 효율적 학습, 전이 학습을 통한 빠른 수렴 속도\n",
        "    단점: 잘못된(품질이 낮은) 데이터 셋 사용 시 성능 저하, (원하는 수준보다)과적합 위험, 기존 학습 지식 손상 가능성\n",
        "\n",
        "다양한 파인튜닝 방법들\n",
        "    Instruction Fine-Tuning(개념)\n",
        "        특정 작업이나 목표를 명확하게 지시하여 학습을 유도\n",
        "        명확한 지시와 예시를 포함한 데이터 셋을 사용하여 학습\n",
        "    Full Fine-Tuning(개념)\n",
        "        모델의 모든 파라미터를 조정하여 특정 작업에 맞게 최적화\n",
        "    Parameter-Efficient Fine-Tuning(구현)\n",
        "        모델의 일부 파라미터만 조정하여 학습 비용과 시간을 줄이는 방법\n",
        "        주요 레이어나 특정 파라미터만 조정\n",
        "    Supervised Fine-Tuning(구현)\n",
        "        지도 학습을 통해 모델을 특정 작업에 맞게 학습\n",
        "\n",
        "LLM이 요구하는 VRAM\n",
        "\n",
        "- Model Distillation(모델 증류)\n",
        "큰 모델의 지식을 작은 모델에 전달하여 작은 모델이 큰 모델의 성능을 최대한 모방하도록 하는 기법\n",
        "작은 모델이 더 적은 자원으로도 높은 성능을 발휘할 수 있도록 함\n",
        "주요 구성: 교사 모델, 학생 모델, 소프트 타겟\n",
        "\n",
        "모델 증류 과정\n",
        "    큰 교사 모델 훈련 및 소프트 타겟(예측 확률 분포) 생성, 학생 모델을 소프트 타겟과 원래 라벨(하드 타겟)을 사용해 훈련\n",
        "장점: 작은 모델은 더 적은 메모리와 계산 자원으로 높은 성능, 자원이 제한된 환경에 배포하기 용이\n",
        "\n",
        "LLM에서 적용\n",
        "    대규모 언어 모델을 증류하여 비슷한 성능을 유지하면서 배포와 실행이 용이\n",
        "    작은 모델은 추론 속도가 빠르기 때문에 실시간 어플리케이션에 유리\n",
        "    훈련 및 배포 시 필요한 컴퓨팅 자원과 전력 소비감소\n",
        "\n",
        "- Quantization(양자화)\n",
        "딥러닝 모델의 메모리와 계산 효율성을 높이기 위한 기술\n",
        "고정 소수점 표현을 사용하여 모델의 가중치와 활성화 값을 표현하는 방식\n",
        "훈련된 모델의 정확성을 최대한 유지하면서도 성능을 개선\n",
        "\n",
        "양자화의 필요성\n",
        "    모델 파라미터의 크기를 줄여 메모리 사용량을 절감\n",
        "    고점 소수점 연산은 부동 소수점 연산에 비해 빠름\n",
        "    낮은 비트 폭(bit-width)으로 연산하면 에너지 소비 감소\n",
        "\n",
        "양자화의 종류: 정적 양자화, 동적 양자화, 훈련 중 양자화\n",
        "\n",
        "정적 양자화\n",
        "    모델 훈련 후 가중치와 활성화 값을 정밀도가 낮은 형식(예: 8비트 정수)으로 변환\n",
        "    메모리 사용량을 줄이고 추론 속도 향상\n",
        "    성능을 유지하며 계산 자원 절감\n",
        "    특징: 모델 훈련이 완료된 후 양자화 적용, 적용이 쉽고 추가 훈련이 요구되지 않음, 파인 튜닝 없이도 안정적인 성능 유지\n",
        "\n",
        "동적 양자화\n",
        "    추론 시점에서 모델의 일부, 전체 가중치와 활성화 값을 정밀도가 낮은 형식으로 변환\n",
        "    런타임 동안 실시간으로 양자화하여, 모델의 성능 저하를 최소화하면서 효율성 극대화\n",
        "    특징: 추론 중 활성화 값을 양자화, 모델의 일부만 양자화하여 메모리 효율성 증대, 추론 시간 단축\n",
        "\n",
        "\n",
        "훈련 중 양자화\n",
        "    훈련 과정에서 양자화 적용\n",
        "    훈련 단계에서 양자화로 인한 손실을 최소화하여 높은 성능 유지\n",
        "    특징: 양자화로 인한 손실을 고려하여 훈련, 가중치와 활성화를 8비트 정수로 변환, 높은 정확도 유지\n",
        "\n",
        "- LoRA and QLoRA\n",
        "LoRA(Low-Rank Adaption)\n",
        "    딥러닝 모델의 미세 조정을 효율적으로 수행하기 위한 기법\n",
        "    기존 모든 파라미터를 저차원 행렬로 모델 파라미터를 분해하여 업데이트\n",
        "    메모리 사용량을 줄이고 계산 효율성을 높임\n",
        "원리\n",
        "\n",
        "장점\n",
        "\n",
        "단점\n",
        "    저차원 행렬로 모델 파라미터를 분해하는 과정이 추가됨에 따라 모델의 구조가 복잡해져서 구현과 유지보수의 어려움이 증가\n",
        "\n",
        "\n",
        "QLoRA\n",
        "    LoRA의 개념을 확장하여 양자화된 모델에 저차원 적응을 적용\n",
        "\n",
        "원리\n",
        "    양자화된 파라미터를 저차원 행렬로 분해하여 LoRA 방식으로 학습 진행\n",
        "    양자화와 저차원 행\n",
        "장점\n",
        "\n",
        "단점\n",
        "\n",
        "\n",
        "- Serving\n",
        "훈련된 모델을 실제 환경에 배포하는 과정\n",
        "단계: 모델 저장, 배포, 예측 요청 처리, 결과 반환\n",
        "\n",
        "모델 저장 및 형식\n",
        "    모델 형식: 딥러닝 모델은 다양한 형식으로 저장 가능\n",
        "    모델 버전 관리: 모델의 버전을 관리하여 업데이트 및 롤백, 유지보수 용이\n",
        "모델 배포\n",
        "    컨테이너화: 컨테이너 기술을 사용하여 배포 환경의 일관성 보장\n",
        "    서버리스 배포: 서버리스 컴퓨팅을 이용하여 모델을 배포\n",
        "    클러스터 배포: 오케스트레이션 도구를 사용하여 모델을 클러스터에 배포\n",
        "예측 요청 처리\n",
        "    API 엔드포인트: RESTful API 또는 gRPC를 사용하여 요청 처리\n",
        "    배치 처리: 대규모 요청을 배치로 처리하여 효율성 확보(묶음으로 요청 및 처리)\n",
        "모니터링 및 로깅\n",
        "    모델 모니터링: 성능을 실시간으로 확인하며 문제 감지\n",
        "    로깅: 예측 요청 및 결과를 로깅하여 추적 및 분석\n",
        "\n",
        "서빙 아키텍처\n",
        "    단일 서버 서빙: 간단한 어플리케이션에 적합, 제한된 요청 처리 능력, 낮은 확장성\n",
        "    분산 서빙: 여러 서버에 모델을 배포하여 요청 처리 능력 확장, 로드 밸런서를 사용해 요청을 분산\n",
        "    서버리스 서빙: 서버리스 플랫폼을 사용하여 자동으로 확장, 사용량에 따라 비용 청구\n",
        "\n",
        "모델 서빙 성능 최적화\n",
        "    모델 최적화: 양자화, 프루닝, 지연 로딩\n",
        "    하드웨어 가속: GPU, TPU\n",
        "\n",
        "paperwithcode를 통해 각 분야의 task 별 트렌드 확인 가능\n",
        "최근 연구 동향 및 모델, 벤치마크 확인 가능\n",
        "'''"
      ]
    }
  ]
}