{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6KHfqCVC7llSP9Kc7YMBm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyeong8465/KTB/blob/main/ktb_ai/ktb_day0722.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ajg7SIFvwros"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "딥러닝2\n",
        "딥러닝은 발전 기술도 빠르고, 상황에 따라 성능도 다르기 때문에 정답은 없다!\n",
        "\n",
        "- 컴퓨터 비전\n",
        "컴퓨터가 디지털 이미지나 비디오에서 의미 있는 정보를 추출하고 해석할 수 있도록 하는 기술\n",
        "\n",
        "컴퓨터 비전의 구성요소\n",
        "픽셀: 이미지의 가장 작은 단위(0~255)\n",
        "그레이 스케일: 흑백 이미지, RGB 채널을 평균 값을 사용하거나 하나의 값만 사용하여 단일 채널로 변환하기도 함\n",
        "\n",
        "- CV & DL\n",
        "Traditional Computer Vision Method\n",
        "특징 추출 알고리즘 기반 (엣지 검출, 코너 추출, SIFT, SURF)\n",
        "\n",
        "DL CV\n",
        "이미지 분류, 객체 검출, 이미지 세분화\n",
        "\n",
        "- CNN\n",
        "이미지와 같은 격자 구조 데이터를 처리하기 위해 설계된 딥러닝 모델\n",
        "이미지 분류, 객체 검출, 이미지 세분화와 같은 컴퓨터 비전 분야에서 뛰어난 성능을 발휘\n",
        "중요한 특징을 자동으로 추출\n",
        "다수의 합성곱 층과 풀링 층을 포함하며, 지역적 특징을 효과적으로 추출(feature extraction)\n",
        "\n",
        "기본 구조: 합성곱 층, 풀링 층, 완전 연결 층, 활성화 함수\n",
        "합성곱과 풀링은 이미지의 특징을 추출하는 단계\n",
        "\n",
        "합성곱 층: 이미지에서 지역적 특징을 추출하는 역할\n",
        "    필터(커널)을 사용하여 입력 이미지에 합성곱 연산을 수행\n",
        "필터: 작은 크기의 행렬로 입력 이미지에 적용되어 특징 맵을 생성\n",
        "스트라이드: 필터가 입력 이미지 위를 이동하는 간격\n",
        "패딩: 출력 크기를 조절하거나 경계 정보 손실을 방지하기 위해 입력 이미지의 가장자리에 추가된 픽셀 값\n",
        "\n",
        "풀링층: 입력 이미지의 공간적 크기를 줄여 계산량을 감소시키고, 모델의 일반화 성능을 향상시키는 역할\n",
        "맥스 풀링: 풀링 영역 내에서 최대값을 선택\n",
        "평균 풀링: 풀링 역역 내에서 평균값을 선택\n",
        "\n",
        "완전 연결 층\n",
        "모든 입력 뉴런이 모든 출력 뉴런과 연결\n",
        "고차원 특징을 결합하여 최종 예측을 수행\n",
        "전통적인 신경망과 유사하게 동작\n",
        "\n",
        "CNN의 작동 원리\n",
        "입력 이미지에 대해 여러 단계의 합성곱과 풀링을 수행하여 점진적으로 추상화된 특징을 추출\n",
        "이미지 입력 -> 합성곱 층 -> 풀링 층 -> 반복 -> 완전 연결 층 -> 출력\n",
        "\n",
        "장점: 필터가 지역적 패턴을 학습하므로, 이미지의 공간적 구조를 효과적으로 활용\n",
        "저차원에서 고차원으로 특징을 점진적으로 학습\n",
        "한계: 대량의 데이터가 필요하다. 데이터가 부족한 경우 과접합이 발생할 수 있다.\n",
        "다수의 합성곱 연산과 다수의 층을 포함하므로, 계산 비용이 높다.\n",
        "딥러닝의 특성상, 높은 성능에도 불구하고 모델의 내부 동작을 해석하는 것이 어렵다.\n",
        "\n",
        "- 주요모델\n",
        "ConvNet(1989)\n",
        "LeNet(1998)\n",
        "AlexNet(2012)\n",
        "GoogLeNet(2014)\n",
        "Inception V2, V3, V4(2014)\n",
        "VGG(2014)\n",
        "ResNet(2015)\n",
        "DenceNet(2016)\n",
        "ResNeXt(2017)\n",
        "Channel Boosted CNN(2018)\n",
        "EfficientNet(2019/20)\n",
        "\n",
        "합성곱에 활성화 함수를 적용하는 이유? 선형 데이터를 비선형 데이터로 변환\n",
        "\n",
        "- LeNet-5\n",
        "1998년에 개발된 CNN, 손글씨 숫자 인식에 사용\n",
        "3개의 합성곱 층과 2개의 풀링 층, 2개의 완전 연결층\n",
        "\n",
        "구조:\n",
        "입력층(32x32) -> 합성곱층(5x5, 6개 필터, 28x28x6) -> 풀링층(2x2, 평균 풀링, 14x14x6)\n",
        "-> 합성곱층(5x5x6, 16개 필터, 10x10x16) -> 풀링층(2x2, 평균 풀링, 5x5x16)\n",
        "-> 합성곱층(5x5x16, 120개 필터, 1x1x120) -> 완전 연결층(입력: 120, 출력: 84)\n",
        "-> 출력층(입력:84, 출력: 10, softmax)\n",
        "\n",
        "장점:\n",
        "이미지의 중요한 특징을 자동으로 학습\n",
        "필터가 지역적 패턴을 학습하여 이미지의 공간적 구조를 효과적으로 활용\n",
        "저차원 데이터에서 고차원으로 특징을 점진적으로 학습하여, 복잡한 패턴도 효과적으로 인식\n",
        "출링 층을 통해 파라미터 수를 줄이고 계산량을 효율적으로 관리\n",
        "\n",
        "단점: 모델 설계와 학습이 복잡, 높은 계산비용, 대량의 데이터 요구\n",
        "\n",
        "- AlexNet\n",
        "ImageNet 우승\n",
        "5개의 합성곱, 3개의 풀링, 3개의 완전 연결 층\n",
        "ReLU와 드롭아웃을 도입하여 성능 향상\n",
        "\n",
        "구조:\n",
        "입력층(227x227x3) -> 1합성곱층(11x11, 96개 필터, 55x55x96, LRN)\n",
        "-> 1풀링층(3x3, 맥스 풀링, 27x27x96) -> 2합성곱층(5x5, 256개 필터, 27x27x256)\n",
        "-> 2풀링층(3x3, 맥스 풀링, 13x13x256) -> 3합성곱층(3x3, 384개 필터, 13x13x384)\n",
        "-> 4합성곱층(3x3, 384개 필터, 13x13x384) -> 5합성곱층(3x3, 256개 필터, 13x13x256)\n",
        "-> 3풀링층(3x3, 맥스 풀링, 6x6x256) -> 1완전 연결층(입력: 9216, 출력: 4096, 드롭아웃)\n",
        "-> 2완전 연결층(입력: 4096, 출력: 4096, 드롭아웃) -> 3완전 연결층(입력: 4096, 출력: 1000, softmax)\n",
        "\n",
        "특징: ReLu, dropout, LRN, data augmetation\n",
        "장점: 대규모 데이터셋 효과적으로 학습 및 높은 성능, ReLU, dropout, LRN, data augmetation\n",
        "단점: 많은 층과 필터로 높은 계산 비용, 많은 메모리, 설계와 학습 복잡\n",
        "\n",
        "\n",
        "- VGGNet\n",
        "신경망의 깊이를 증가시켜 성능을 향상시켰다.\n",
        "작은 필터를 여러번 사용하여 매개변수가 줄어들고, 더 복잡한 패턴을 학습 가능\n",
        "\n",
        "VGGNet-16 구조:\n",
        "입력층(224x224x3)\n",
        "block1: 3x3, 64개 필터를 갖는 합성곱층 2개/ 2x2, 스트라이드 2의 최대풀링층 1개\n",
        "block2: 3x3, 128개 필터를 갖는 합성곱층 2개/ 2x2, 스트라이드 2의 최대풀링층 1개\n",
        "block3: 3x3, 256개 필터를 갖는 합성곱층 3개/ 2x2, 스트라이드 2의 최대풀링층 1개\n",
        "block4: 3x3, 512개 필터를 갖는 합성곱층 3개/ 2x2, 스트라이드 2의 최대풀링층 1개\n",
        "block5: 3x3, 512개 필터를 갖는 합성곱층 3개/ 2x2, 스트라이드 2의 최대풀링층 1개\n",
        "완전 연결층: 4096개의 뉴런, dropout 0.5의 완전연결층 2개/ 1000개의 뉴런, softmax를 갖는 완전 연결층 1개\n",
        "\n",
        "특징: 작은 필터를 사용하여 신경망의 깊이 증가, 심층구조, ReLu, dropout\n",
        "장점: 더 깊은 구조로 성능 향상\n",
        "단점: 많은 층과 필터로 높은 계산 비용, 많은 메모리, 설계와 학습 복잡\n",
        "\n",
        "- ResNet\n",
        "깊은 신경망 학습 시 발생하는 기울기 소실 문제를 해결하기 위해 잔차 연결 도입\n",
        "VGG-19의 구조를 이어받음\n",
        "\n",
        "특징: 잔차 연결, 병목 블록, 배치 정규화, 심증 구조\n",
        "장점: 잔차 연결을 통해 기울기 소실 문제 완화하여 깊은 신경망을 효과적으로 학습, 병목 블록을 사용하여 연산 효울성을 높이고 더 깉은 네트워크 설계 가능\n",
        "단점: 많은 층과 필터로 높은 계산 비용, 많은 메모리, 설계와 학습 복잡\n",
        "\n",
        "- SSD\n",
        "객체 검출 모델, 여러 객체의 위치와 클래스 동시 예측\n",
        "VGG-16의 구조를 이어받음, ResNet 모델 구조로 대체되는 경우도 있음\n",
        "\n",
        "주요개념: 싱글 샷 검출, 멀티스케일 특징 맵, 디폴트 박스\n",
        "\n",
        "구조\n",
        "기본 네트워크: 사전 학습 모델 사용, 기본 네트워크의 마지막 몇 층을 제거하고 합성곱 층을 추가해서 사용\n",
        "추가 합성곱 층: 기본 네트워크 위에 여러 합성곱 층을 추가하여 다양한 크기의 특징 맵을 생성\n",
        "멀티 스케일 특징 맵: 다양한 크기의 특징 맵을 통해 객체 검출\n",
        "\n",
        "장점: 단일 패스로 객체 검출을 수행하므로 빠름, 다양한 크기의 특징 맵을 사용하여 다양한 크기의 객체를 효과적으로 검출, 단일 싱경망으로 모든 예측을 수행하므로 구현이 상대적으로 간단\n",
        "단점: 작은 객체를 검출하기 어려움, 높은 메모리 사용량\n",
        "\n",
        "\n",
        "\n",
        "라이센스 문제가 없다면 직접 구현 및 학습하는 것보다 사전학습 모델을 사용하는게 서비스 측면에서는 더 효율적일 수 있다.\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#실습\n",
        "SSD의 기본 구조 이해: SSD의 기본 원리와 구조 이해  \n",
        "사전 학습된 모델 사용: 사전 학습된 SSD 모델을 사용하여 이미지에서 객체 검출  \n",
        "실제 데이터셋 사용: COCO와 같은 실제 데이터 셋을 사용하여 SSD 모델을 학습시키고 평가  \n",
        "결과 시각화: 검출된 객체를 이미지에 시각화하여 결과 확인"
      ],
      "metadata": {
        "id": "KeWYmwFa6wGK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MemNdBA_6v21"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}